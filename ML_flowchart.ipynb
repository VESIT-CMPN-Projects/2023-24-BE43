{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zvZeeLW25hi",
        "outputId": "8792ce6f-cf38-4aae-85f7-766295eec5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tensorflow  # Replace tensorflow with torch if using PyTorch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
        "data = pd.read_csv('flowchart-mermaid.csv')"
      ],
      "metadata": {
        "id": "qCf2ScQ_Nrqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "FE_QI9tSNtEW",
        "outputId": "f8da6f82-f38f-4b21-8350-712b6d85f0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Prompt  \\\n",
              "0                    Implement Bubble Sort algorithm.   \n",
              "1           Design and implement QuickSort algorithm.   \n",
              "2            Perform Binary Search on a sorted array.   \n",
              "3                Merge two sorted arrays efficiently.   \n",
              "4   Calculate the factorial of a number using recu...   \n",
              "..                                                ...   \n",
              "89                                            OR Gate   \n",
              "90                                           NOT Gate   \n",
              "91                                          NAND Gate   \n",
              "92                                           NOR Gate   \n",
              "93                                         EX-OR Gate   \n",
              "\n",
              "                                         Mermaid_code  \n",
              "0   graph TD\\n    A((Start)) --> B[/\"Initialize i=...  \n",
              "1   graph TD\\n    A((Start)) --> B[\"Choose Pivot\"]...  \n",
              "2   graph TD\\r\\n    A((Start)) --> B[\"Input sorted...  \n",
              "3   graph TD\\n    A --> B[/\"Initialize indices i, ...  \n",
              "4   graph TD\\n    A((Start)) --> B[/\"Input number ...  \n",
              "..                                                ...  \n",
              "89  graph TD;\\r\\n    A((Start)) --> B(\"OR Gate\");\\...  \n",
              "90  graph TD;\\r\\n    A((Start)) --> B(\"NOT Gate\");...  \n",
              "91  graph TD;\\r\\n    A((Start)) --> B(\"NAND Gate\")...  \n",
              "92  graph TD;\\r\\n    A((Start)) --> B(\"NAND Gate\")...  \n",
              "93  graph TD;\\r\\n    A((Start)) --> B(\"EX-OR Gate\"...  \n",
              "\n",
              "[94 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0faa457-b87e-4bbe-8003-70f8346ae714\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Mermaid_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Implement Bubble Sort algorithm.</td>\n",
              "      <td>graph TD\\n    A((Start)) --&gt; B[/\"Initialize i=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Design and implement QuickSort algorithm.</td>\n",
              "      <td>graph TD\\n    A((Start)) --&gt; B[\"Choose Pivot\"]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Perform Binary Search on a sorted array.</td>\n",
              "      <td>graph TD\\r\\n    A((Start)) --&gt; B[\"Input sorted...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Merge two sorted arrays efficiently.</td>\n",
              "      <td>graph TD\\n    A --&gt; B[/\"Initialize indices i, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Calculate the factorial of a number using recu...</td>\n",
              "      <td>graph TD\\n    A((Start)) --&gt; B[/\"Input number ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>OR Gate</td>\n",
              "      <td>graph TD;\\r\\n    A((Start)) --&gt; B(\"OR Gate\");\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>NOT Gate</td>\n",
              "      <td>graph TD;\\r\\n    A((Start)) --&gt; B(\"NOT Gate\");...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>NAND Gate</td>\n",
              "      <td>graph TD;\\r\\n    A((Start)) --&gt; B(\"NAND Gate\")...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>NOR Gate</td>\n",
              "      <td>graph TD;\\r\\n    A((Start)) --&gt; B(\"NAND Gate\")...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>EX-OR Gate</td>\n",
              "      <td>graph TD;\\r\\n    A((Start)) --&gt; B(\"EX-OR Gate\"...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0faa457-b87e-4bbe-8003-70f8346ae714')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0faa457-b87e-4bbe-8003-70f8346ae714 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0faa457-b87e-4bbe-8003-70f8346ae714');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5159d4a5-6d26-4df7-a961-9e9f03543b32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5159d4a5-6d26-4df7-a961-9e9f03543b32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5159d4a5-6d26-4df7-a961-9e9f03543b32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 94,\n  \"fields\": [\n    {\n      \"column\": \"Prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Design a process scheduling algorithm with priority levels.\",\n          \"Schedule processes using Round Robin algorithm.\",\n          \"Execute the AES algorithm for symmetric-key encryption.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mermaid_code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"graph TD\\r\\n    A((Start))\\r\\n    B[\\\"Define process priority levels\\\"]\\r\\n    C(\\\"()Run process scheduling algorithm\\\")\\r\\n    D[\\\"Execute highest priority process\\\"]\\r\\n    E[\\\"Handle process termination or preemption\\\"]\\r\\n    F((End))\\r\\n\\r\\n    A -->|1| B\\r\\n    B -->|2| C\\r\\n    C -->|3| D\\r\\n    D -->|4| E\\r\\n    E -->|5| C\\r\\n    E -->|6| F\\r\",\n          \"graph TD\\r\\n    A((Start))\\r\\n    B[\\\"Initialize ready queue with processes\\\"]\\r\\n    C[\\\"While there are processes in the ready queue\\\"]\\r\\n    D[\\\"Dequeue the first process\\\"]\\r\\n    E[\\\"Execute the process for a time quantum\\\"]\\r\\n    F[\\\"Check if the process is completed\\\"]\\r\\n    G[\\\"If not, enqueue the process back into the ready queue\\\"]\\r\\n    H[\\\"Repeat until all processes are completed\\\"]\\r\\n    I((End))\\r\\n\\r\\n    A -->|1| B\\r\\n    B -->|2| C\\r\\n    C -->|3| D\\r\\n    D -->|4| E\\r\\n    E -->|5| F\\r\\n    F -->|6| G\\r\\n    G -->|7| C\\r\\n    F -->|8| I\\r\",\n          \"graph TD\\r\\n    A((Start))\\r\\n    B[\\\"Choose key (K) and plaintext (P)\\\"]\\r\\n    C[\\\"Round Key Generation\\\"]\\r\\n    D[\\\"Initial Round: AddRoundKey\\\"]\\r\\n    E[\\\"Main Rounds: SubBytes, ShiftRows, MixColumns, AddRoundKey\\\"]\\r\\n    F[\\\"Final Round: SubBytes, ShiftRows, AddRoundKey\\\"]\\r\\n    G[\\\"Ciphertext (C)\\\"]\\r\\n    H((End))\\r\\n\\r\\n    A -->|1| B\\r\\n    B -->|2| C\\r\\n    C -->|3| D\\r\\n    D -->|4| E\\r\\n    E -->|5| F\\r\\n    F -->|6| G\\r\\n    G -->|7| H\\r\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EdXaGJE29mj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Choose a BART model size (e.g., facebook/bart-base)\n",
        "model_name = \"facebook/bart-base\"\n",
        "bart_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4Fo420B8IsV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "f8820181c65b44f794d90b1b3880a210",
            "149e2723a3904917b10669eba70acec1",
            "18358d2c1ef5488a9ec0b95e76cdbf5b",
            "38019b9303524216b5e722a849168899",
            "21eb99198ddf4f99943fa8974ee46992",
            "4f63418571ae4a06b7c65f654816dfd5",
            "c777542fac0c46238447e0424d54b033",
            "46e84d8d755a4e24a2db7752052862af",
            "37b9cb998f0c40cb949b63d5ac36c2ca",
            "cb1935a77e2243b48214e8646ca91c21",
            "b3903f62af3e493a8143fe3e3419ec9a",
            "f5bed83e801843cc967b8bf6cfea9049",
            "f42f347a25ba473dbc35bbc5ad5f2af6",
            "945eed4f884f4d6384be80c119724b9b",
            "fb5a4e6268074fcebdf1fc44de39dca8",
            "4570bf4207834f0b91ea8c8a03065712",
            "13bf6b132e544dcfa32b100e9d7142fb",
            "5f774e82b0ee49f3b26aeb625da916fc",
            "e307ef6433cb4eb3bd300bd70b8db3d0",
            "b792cd3e97e1441fbc6cb6b9d43083c5",
            "12b32d3b2e3644b8b5a74f1f0d46e017",
            "d18c64acd0174e589c963438b44ef012",
            "91bd9dd7c9b1446990c6749376e99c03",
            "7fc2ca54083049cbb2b31b966a24a533",
            "088b763ae19b420397caff9644488f2d",
            "f7a01d9838b14204aeeb6d37b48cf118",
            "faea9eeb151c4cf49987e9c5a7409485",
            "8f8d3d4b126744429cb5e4f535b3629f",
            "add7944ef6d64ce2b231dd53f3d177ed",
            "79735f8d946c45e8960d084c06fefb6f",
            "cd2bd90064e14a11b7a2669c17e4bc14",
            "5f5bcee0be7c434294000fed76d53a30",
            "f44884fe540f458ebf1eae647b3b9463",
            "57ea9c64588e460f8e9bb27a52cb709e",
            "cde0b2ddea4646578cc687ee196c136c",
            "d31e2bcff9594aadbf1445d469ca115b",
            "1c6ec0bc25b94f05b3e2d73e088d9acf",
            "42c03bfbf5744103a25ec4f56a83a65a",
            "343f7c7b826145d49e1d1b47795b8a98",
            "446e32d428314b4487cb570f12a8e9cf",
            "3c828767deb74a60bae801fba1d45260",
            "a23ad9ef5b5f454baf7a6f34035a0a6f",
            "d96247457ece4f5e8aa656374a63aad9",
            "a533b5e53b9242de8e4e6fc747684759",
            "3ba55f08e05a484f9211fb0667a3ec9d",
            "167d7760959e4ce7a594b2898b59ff39",
            "c2cc832b705d4eaaa0010a56af8780e0",
            "e296dfaa8958467697ee0f1235514208",
            "ba639df59a954c2896beb9055658e973",
            "cf03f3749ab0425792ce161674018194",
            "dccec88eb1504ffc863ad3922b211969",
            "b3169bcec34946b0a4d3930a1d8659c0",
            "c913193c4f5c4944baca8fb4b5d0052b",
            "b293eafc38d44d4aa6db5832f8510389",
            "1e2b748b039a4a6cbd64e410bb540d49",
            "d269f4ba3bb3438ba84bf3736d5cb903",
            "7f9113ef9eb746bcb335061ed44393bc",
            "d9d42c144c9847eb921c714416606478",
            "b38a1264d2ee4ea783154c218923d738",
            "1336d10ea7cc42209efe0ca512fbae5e",
            "1dcf81fdc8e147a48381cf0be0e140ff",
            "db6505c8efdb4bd581a1b91153e6a6a3",
            "ed63128bd1c040388d6f93b80e0a8662",
            "e31137e682b44f95ae88f7557fcc1ee4",
            "39af302553634ea08355daf92f9724ef",
            "18a714d9eacd4df8ba58c329549ea098"
          ]
        },
        "outputId": "3d10eef6-b86b-4d12-c42a-d58a2cc53f12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8820181c65b44f794d90b1b3880a210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5bed83e801843cc967b8bf6cfea9049"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91bd9dd7c9b1446990c6749376e99c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57ea9c64588e460f8e9bb27a52cb709e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ba55f08e05a484f9211fb0667a3ec9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d269f4ba3bb3438ba84bf3736d5cb903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d00c4a33f433>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Generate Mermaid codes using the pre-trained BART model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgenerated_mermaid_codes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Convert token IDs back to text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1414\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1205\u001b[0m                     )\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m   1208\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \"\"\"\n\u001b[1;32m    661\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         hidden_states, attn_weights, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#too much time, but more accuracy\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess prompts and Mermaid codes\n",
        "data[\"Prompt\"] = data[\"Prompt\"].astype(str).str.lower()\n",
        "data[\"Mermaid_code\"] = data[\"Mermaid_code\"].astype(str)\n",
        "\n",
        "# Tokenize prompts\n",
        "tokenized_prompts = tokenizer(data[\"Prompt\"].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate Mermaid codes using the pre-trained BART model\n",
        "generated_mermaid_codes = model.generate(**tokenized_prompts)\n",
        "\n",
        "# Convert token IDs back to text\n",
        "generated_mermaid_codes_text = tokenizer.batch_decode(generated_mermaid_codes, skip_special_tokens=True)\n",
        "\n",
        "# Evaluate the generated Mermaid codes\n",
        "for i, (prompt, generated_code) in enumerate(zip(data[\"Prompt\"], generated_mermaid_codes_text)):\n",
        "    print(f\"Prompt {i+1}: {prompt}\")\n",
        "    print(f\"Generated Mermaid Code: {generated_code}\")\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq8dZW8FFk8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965ea259-3154-475e-fa38-f6e4bf9ef4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a prompt from the dataset: Calculate the factorial of a number using recursion.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Prompt: calculate the factorial of a number using recursion.\n",
            "Corresponding Original Mermaid Code: graph TD\n",
            "    A((Start)) --> B[/\"Input number n\"/]\n",
            "    B --> C(\"Base case: n=0 or n=1?\")\n",
            "    C -->|Yes| D[\"Factorial is 1\"]\n",
            "    C -->|No| E[\"Recursively call factorial(n-1)\"]\n",
            "    E --> F[\"Multiply result by n\"]\n",
            "    F --> G[\"Output Factorial\"]\n",
            "    G --> H((End))\n",
            "\n",
            "Generated Mermaid Code: calculate the factorial of a number using recursion.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# User enters a prompt from the dataset\n",
        "user_prompt = input(\"Enter a prompt from the dataset: \").lower()\n",
        "\n",
        "# Find the corresponding Mermaid code in the dataset\n",
        "corresponding_mermaid_code = data[data[\"Prompt\"].str.lower() == user_prompt][\"Mermaid_code\"].values\n",
        "\n",
        "# Tokenize the user's prompt\n",
        "tokenized_user_prompt = tokenizer(user_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate Mermaid code using the pre-trained BART model\n",
        "generated_mermaid_code = model.generate(**tokenized_user_prompt)\n",
        "\n",
        "# Convert token IDs back to text\n",
        "generated_mermaid_code_text = tokenizer.batch_decode(generated_mermaid_code, skip_special_tokens=True)\n",
        "\n",
        "# Print the results\n",
        "print(f\"User Prompt: {user_prompt}\")\n",
        "if len(corresponding_mermaid_code) > 0:\n",
        "    print(f\"Corresponding Original Mermaid Code: {corresponding_mermaid_code[0]}\")\n",
        "else:\n",
        "    print(\"Prompt not found in the dataset.\")\n",
        "print(f\"Generated Mermaid Code: {generated_mermaid_code_text[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogDJDb82Bwts",
        "outputId": "379d0d5f-e9ad-41fb-b6d5-e2db3084c38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt 1: implement bubble sort algorithm.\n",
            "Generated Mermaid Code: implementieren bubble sort algorithm.\n",
            "==================================================\n",
            "Prompt 2: design and implement quicksort algorithm.\n",
            "Generated Mermaid Code: Design und implement schnellsort algorithm.\n",
            "==================================================\n",
            "Prompt 3: perform binary search on a sorted array.\n",
            "Generated Mermaid Code: effectuer binary search on a binary array.\n",
            "==================================================\n",
            "Prompt 4: merge two sorted arrays efficiently.\n",
            "Generated Mermaid Code: Zusammenfügen Sie zwei sortierte Arrays effizient.\n",
            "==================================================\n",
            "Prompt 5: calculate the factorial of a number using recursion.\n",
            "Generated Mermaid Code: Calculez le factorial d'un nombre en utilisant la recursion\n",
            "==================================================\n",
            "Prompt 6: implement depth-first search (dfs) algorithm.\n",
            "Generated Mermaid Code: Implement the depth-first search algorithm (dfs) algorithm.\n",
            "==================================================\n",
            "Prompt 7: design and implement dijkstra's algorithm for shortest path.\n",
            "Generated Mermaid Code: design and implement dijkstra's algorithm for shortest path.\n",
            "==================================================\n",
            "Prompt 8: implement the merge sort algorithm.\n",
            "Generated Mermaid Code: implementieren Sie das merge sort algorithm.\n",
            "==================================================\n",
            "Prompt 9: solve the traveling salesman problem using a suitable algorithm.\n",
            "Generated Mermaid Code: Lösung der Reise Reise salesman problem mit einem passenden algorithm.\n",
            "==================================================\n",
            "Prompt 10: design and implement the knapsack problem solution.\n",
            "Generated Mermaid Code: Konzipieren und implementieren die Lösung für die Problemlösung knapsack.\n",
            "==================================================\n",
            "Prompt 11: perform a complexity analysis for a given algorithm.\n",
            "Generated Mermaid Code: perform a complex analysis for a given algorithm.\n",
            "==================================================\n",
            "Prompt 12: develop an algorithm for finding the longest common subsequence (lcs).\n",
            "Generated Mermaid Code: develop an algorithm for finding the longest common subsequence (lcs).\n",
            "==================================================\n",
            "Prompt 13: implement the breadth-first search (bfs) algorithm for a graph.\n",
            "Generated Mermaid Code: the search algorithm for a graph.\n",
            "==================================================\n",
            "Prompt 14: design and analyze an algorithm for finding the shortest common supersequence (scs).\n",
            "Generated Mermaid Code: design and analyze an algorithm for finding the shortest common supersequence (s\n",
            "==================================================\n",
            "Prompt 15: solve the maximum subarray problem using an efficient algorithm.\n",
            "Generated Mermaid Code: Soluure a l'optimisation en utilisant un algorithm effizient,\n",
            "==================================================\n",
            "Prompt 16: implement the floyd-warshall algorithm for all pairs shortest paths.\n",
            "Generated Mermaid Code: a flidd-warshall algorithm for all pairs shortest\n",
            "==================================================\n",
            "Prompt 17: design and analyze an algorithm for finding articulation points in a graph.\n",
            "Generated Mermaid Code: Design and analyze an algorithm for finding articulation points in a graph.\n",
            "==================================================\n",
            "Prompt 18: solve the 0/1 knapsack problem using dynamic programming.\n",
            "Generated Mermaid Code: Lösung der Problem 0/1 knapsack mit dynamic programming.\n",
            "==================================================\n",
            "Prompt 19: implement a randomized algorithm for finding the median of an array.\n",
            "Generated Mermaid Code: a randomised algorithm for finding the median of an array.\n",
            "==================================================\n",
            "Prompt 20: design and analyze an algorithm for finding strongly connected components in a directed graph.\n",
            "Generated Mermaid Code: Design and analyze a design and analysis of a design and analysis of a design and\n",
            "==================================================\n",
            "Prompt 21: solve the maximum flow problem using algorithms like ford-fulkerson.\n",
            "Generated Mermaid Code: Sol Soluu der maximal flow problem mit algorithmen wie ford-fulkerson.\n",
            "==================================================\n",
            "Prompt 22: implement the rabin-karp algorithm for string matching.\n",
            "Generated Mermaid Code: Implementieren Sie das rabin-karp algorithm für string matching.\n",
            "==================================================\n",
            "Prompt 23: schedule processes using round robin algorithm.\n",
            "Generated Mermaid Code: - - - - - - - - - \n",
            "==================================================\n",
            "Prompt 24: manage memory using paging technique.\n",
            "Generated Mermaid Code: Speicherverwaltung mit paging Technik.\n",
            "==================================================\n",
            "Prompt 25: implement file operations (create, read, write, delete).\n",
            "Generated Mermaid Code: Implement file operations (create, read, write, delete).\n",
            "==================================================\n",
            "Prompt 26: handle process synchronization using semaphores.\n",
            "Generated Mermaid Code: synchronization synchronization using semaphores.\n",
            "==================================================\n",
            "Prompt 27: implement demand paging in virtual memory.\n",
            "Generated Mermaid Code: Implement the demand paging in virtual memory.\n",
            "==================================================\n",
            "Prompt 28: design and implement a shell program.\n",
            "Generated Mermaid Code: Concevoir und implement a shell program.\n",
            "==================================================\n",
            "Prompt 29: perform process communication using message passing.\n",
            "Generated Mermaid Code: - - - - - - - - - \n",
            "==================================================\n",
            "Prompt 30: solve a system of linear equations using gaussian elimination.\n",
            "Generated Mermaid Code: linear equations by using gaussian elimination.\n",
            "==================================================\n",
            "Prompt 31: evaluate a definite integral using numerical methods.\n",
            "Generated Mermaid Code: evaluieren a qualitative qualitative quantitative quantitative quantitative quantitative quantitative quantitative quantitative quantitative quantitative quantitative quantitative\n",
            "==================================================\n",
            "Prompt 32: solve a first-order ordinary differential equation.\n",
            "Generated Mermaid Code: Solsolvieren Sie eine einfache Lösung einer differential equation in der einfachen einfachen einfachen\n",
            "==================================================\n",
            "Prompt 33: find the inverse of a matrix using elementary row operations.\n",
            "Generated Mermaid Code: the inverse of a matrix using elementary row operations.\n",
            "==================================================\n",
            "Prompt 34: apply the chain rule to differentiate a composite function.\n",
            "Generated Mermaid Code: appliquent die chain rule to differentiate a composite function.\n",
            "==================================================\n",
            "Prompt 35: solve a trigonometric equation.\n",
            "Generated Mermaid Code: Solsolvieren Sie eine trigonometrische equation.\n",
            "==================================================\n",
            "Prompt 36: compute eigenvalues and eigenvectors of a matrix.\n",
            "Generated Mermaid Code: .\n",
            "==================================================\n",
            "Prompt 37: implement a deadlock detection and recovery mechanism.\n",
            "Generated Mermaid Code: Implement implement a deadlock detection and recovery mechanism.\n",
            "==================================================\n",
            "Prompt 38: design and implement a file allocation table (fat) system.\n",
            "Generated Mermaid Code: and implement a file allocation table (fat) system.\n",
            "==================================================\n",
            "Prompt 39: execute the banker's algorithm for deadlock avoidance.\n",
            "Generated Mermaid Code: - execute the banker's algorithm for deadlock avoidance.\n",
            "==================================================\n",
            "Prompt 40: implement a page replacement algorithm (e.g., lru, fifo).\n",
            "Generated Mermaid Code: lru, fifo).\n",
            "==================================================\n",
            "Prompt 41: design a process scheduling algorithm with priority levels.\n",
            "Generated Mermaid Code: Concevoir un algorithm de scheduling des processus, en utilisant les priorités.\n",
            "==================================================\n",
            "Prompt 42: develop a system call for inter-process communication (ipc).\n",
            "Generated Mermaid Code: Entwickler Entwickler Entwickler Entwickler Entwickler Entwickler Entwickler Entwickler Entwickler \n",
            "==================================================\n",
            "Prompt 43: execute the least recently used (lru) page replacement policy.\n",
            "Generated Mermaid Code: - - - - - - - - - \n",
            "==================================================\n",
            "Prompt 44: implement virtual memory management using paging.\n",
            "Generated Mermaid Code: Implement virtual memory management using paging.\n",
            "==================================================\n",
            "Prompt 45: design and analyze the process creation and termination mechanism.\n",
            "Generated Mermaid Code: Konzipieren und analysieren die Prozesse, die die Prozesse, die die Prozesse\n",
            "==================================================\n",
            "Prompt 46: develop a memory-mapped file mechanism in an operating system.\n",
            "Generated Mermaid Code: a mechanism for memory-mapped file-mechanisme in a operating system.\n",
            "==================================================\n",
            "Prompt 47: execute a disk scheduling algorithm (e.g., scan, c-scan).\n",
            "Generated Mermaid Code: a disk scheduling algorithm (e.g. scan, c-scan).\n",
            "==================================================\n",
            "Prompt 48: implement a system call for creating and managing threads.\n",
            "Generated Mermaid Code: a system call for creating and managing threads.\n",
            "==================================================\n",
            "Prompt 49: design and implement a file system with support for directories.\n",
            "Generated Mermaid Code: Concevoir und implementieren ein filesystem mit Unterstützung für Verzeichnungen.\n",
            "==================================================\n",
            "Prompt 50: execute the belady's anomaly scenario in page replacement.\n",
            "Generated Mermaid Code: - execute the belady's anomaly scenario in page replacement.\n",
            "==================================================\n",
            "Prompt 51: develop a priority inversion solution in real-time systems.\n",
            "Generated Mermaid Code: Entwicklung einer Priorität inversion Lösung in Echtzeitsystemen.\n",
            "==================================================\n",
            "Prompt 52: execute the diffie-hellman key exchange algorithm.\n",
            "Generated Mermaid Code: execute the diffie-hellman key exchange algorithm.\n",
            "==================================================\n",
            "Prompt 53: implement the rsa algorithm for public-key encryption.\n",
            "Generated Mermaid Code: Implement the rsa algorithm for public-key encryption.\n",
            "==================================================\n",
            "Prompt 54: design and implement a secure hash function.\n",
            "Generated Mermaid Code: Conception and implementation of a secure hash function.\n",
            "==================================================\n",
            "Prompt 55: develop a digital signature generation and verification process.\n",
            "Generated Mermaid Code: Entwicklung der Entwicklung eines Prozess zur Erzeugung und Verifizierung digitaler Signaturen.\n",
            "==================================================\n",
            "Prompt 56: execute the aes algorithm for symmetric-key encryption.\n",
            "Generated Mermaid Code: . Execute the aes algorithm for symmetric-key encryption.\n",
            "==================================================\n",
            "Prompt 57: implement a secure communication protocol using ssl/tls.\n",
            "Generated Mermaid Code: Implement a secure communication protocol using ssl/tls.\n",
            "==================================================\n",
            "Prompt 58: design and analyze a public-key infrastructure (pki).\n",
            "Generated Mermaid Code: and analyze a public-key infrastructure (pki).\n",
            "==================================================\n",
            "Prompt 59: develop a secure password hashing mechanism.\n",
            "Generated Mermaid Code: Entwicklung eine einheitliche Technologie, die die Entwicklung eines einheitlichen Technologie,\n",
            "==================================================\n",
            "Prompt 60: implement a basic intrusion detection system (ids).\n",
            "Generated Mermaid Code: Implementation of a basic intrusion detection system (ids)\n",
            "==================================================\n",
            "Prompt 61: design and construct a secure file encryption system.\n",
            "Generated Mermaid Code: Concevoir und construct a secure file encryption system.\n",
            "==================================================\n",
            "Prompt 62: linearity of laplace transform\n",
            "Generated Mermaid Code: linearity of linearity of laplace transform\n",
            "==================================================\n",
            "Prompt 63: first shifting theorem\n",
            "Generated Mermaid Code: \n",
            "==================================================\n",
            "Prompt 64: second shifting theorem\n",
            "Generated Mermaid Code: a\n",
            "==================================================\n",
            "Prompt 65: change of scale property\n",
            "Generated Mermaid Code: Change of scale property\n",
            "==================================================\n",
            "Prompt 66: multiplication by t\n",
            "Generated Mermaid Code: multiplication by t\n",
            "==================================================\n",
            "Prompt 67: division by t\n",
            "Generated Mermaid Code: t\n",
            "==================================================\n",
            "Prompt 68: laplace transform of derivative\n",
            "Generated Mermaid Code: transform laplace transform of derivative\n",
            "==================================================\n",
            "Prompt 69: laplace transform of integral\n",
            "Generated Mermaid Code: transform laplace transform transform integral\n",
            "==================================================\n",
            "Prompt 70: convolution of two functions\n",
            "Generated Mermaid Code: convolution of two functions\n",
            "==================================================\n",
            "Prompt 71: inverse laplace transform\r\n",
            "\n",
            "Generated Mermaid Code: inverse transformation laplace\n",
            "==================================================\n",
            "Prompt 72: inverse laplace transform using partial fractions, derivatives property:\n",
            "Generated Mermaid Code: inverse laplace transform using partial fractions, derivatives property:\n",
            "==================================================\n",
            "Prompt 73: inverse laplace transform using convolution property:\n",
            "Generated Mermaid Code: inverse laplace transform using convolution property:\n",
            "==================================================\n",
            "Prompt 74: applications to solve initial and boundary value problems involving ordinary differential equations:\n",
            "Generated Mermaid Code: to solve initial and boundary value problems involving ordinary differential equations:\n",
            "==================================================\n",
            "Prompt 75: complex integration\n",
            "Generated Mermaid Code: Integration complex\n",
            "==================================================\n",
            "Prompt 76: taylor’s and laurent’s series expansion:\n",
            "Generated Mermaid Code: taylor’s and laurent’s series expansion:\n",
            "==================================================\n",
            "Prompt 77: definition of singularity, zeroes, poles of f(z), residues, cauchy’s residue theorem:\n",
            "Generated Mermaid Code: definition of singularity, zeroes, poles of f(z), residue\n",
            "==================================================\n",
            "Prompt 78: z-transform\n",
            "Generated Mermaid Code: z-transform\n",
            "==================================================\n",
            "Prompt 79: logic in discrete structures & graph theory\r\n",
            "\r\n",
            "propositional logic\r\n",
            "laws of logic\r\n",
            "normal forms\r\n",
            "inference theory of predicate calculus\r\n",
            "mathematical induction\n",
            "Generated Mermaid Code: logic in discrete structures & graph theory propositional logic laws of logic normal forms inference\n",
            "==================================================\n",
            "Prompt 80: relations and functions\n",
            "\n",
            "basic concepts of set theory\n",
            "relations: definition, types, representation, equivalence relations, equivalence classes\n",
            "functions: definition, types, composition, identity and inverse function\n",
            "Generated Mermaid Code: and functions basic concepts of set theory relations: definition, types, representation, equi\n",
            "==================================================\n",
            "Prompt 81: counting\r\n",
            "\r\n",
            "basic counting principle: sum rule, product rule\r\n",
            "recurrence relations\n",
            "Generated Mermaid Code: Count counting basic counting principle: sum rule, product rule recurrence relations\n",
            "==================================================\n",
            "Prompt 82: graphs\r\n",
            "\r\n",
            "types of graphs\r\n",
            "graph representation\r\n",
            "operations on graphs\r\n",
            "walk, path, circuit\r\n",
            "connected graphs, disconnected graph\r\n",
            "components\r\n",
            "euler and hamiltonian graphs\r\n",
            "planar graph\n",
            "Generated Mermaid Code: graphs types of graphs graph representation operations on graphs walk, path, circuit connected\n",
            "==================================================\n",
            "Prompt 83: introduction to data structures\r\n",
            "\r\n",
            "introduction to pointers and structures in c\r\n",
            "introduction to data structures - concept of adt; types of data structures\r\n",
            "introduction to stack - adt of stack; operations on stack\r\n",
            "introduction to queue - adt of queue; operations on queue\r\n",
            "introduction to linked list - representation of linked list; types of linked list\n",
            "Generated Mermaid Code: introduction to data structures introduction to pointers and structures in c introduction to data structures introduction\n",
            "==================================================\n",
            "Prompt 84: singly linkedlist\n",
            "Generated Mermaid Code: a singly linkedlist\n",
            "==================================================\n",
            "Prompt 85: circular linkedlist\n",
            "Generated Mermaid Code: circular circular circular circular circular circular circular linkedlist\n",
            "==================================================\n",
            "Prompt 86: binary tree\n",
            "Generated Mermaid Code: binary tree\n",
            "==================================================\n",
            "Prompt 87: nan\n",
            "Generated Mermaid Code: nan\n",
            "==================================================\n",
            "Prompt 88: linear search\n",
            "Generated Mermaid Code: linear search\n",
            "==================================================\n",
            "Prompt 89: and gate\n",
            "Generated Mermaid Code: gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate\n",
            "==================================================\n",
            "Prompt 90: or gate\n",
            "Generated Mermaid Code: gate gate or\n",
            "==================================================\n",
            "Prompt 91: not gate\n",
            "Generated Mermaid Code: gate\n",
            "==================================================\n",
            "Prompt 92: nand gate\n",
            "Generated Mermaid Code: gate\n",
            "==================================================\n",
            "Prompt 93: nor gate\n",
            "Generated Mermaid Code: gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate gate\n",
            "==================================================\n",
            "Prompt 94: ex-or gate\n",
            "Generated Mermaid Code: gate gate\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#less accurate\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
        "data = pd.read_csv('flowchart-mermaid.csv')\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess prompts\n",
        "data[\"Prompt\"] = data[\"Prompt\"].astype(str).str.lower()\n",
        "\n",
        "# Tokenize prompts\n",
        "tokenized_prompts = tokenizer(data[\"Prompt\"].tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate Mermaid codes using the pre-trained T5 model\n",
        "generated_mermaid_codes = model.generate(**tokenized_prompts)\n",
        "\n",
        "# Convert token IDs back to text\n",
        "generated_mermaid_codes_text = tokenizer.batch_decode(generated_mermaid_codes, skip_special_tokens=True)\n",
        "\n",
        "# Evaluate the generated Mermaid codes\n",
        "for i, (prompt, generated_code) in enumerate(zip(data[\"Prompt\"], generated_mermaid_codes_text)):\n",
        "    print(f\"Prompt {i+1}: {prompt}\")\n",
        "    print(f\"Generated Mermaid Code: {generated_code}\")\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_FLdt4-EDhJ",
        "outputId": "cc41fb8e-66c4-45c6-ca06-43186b2e1510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a prompt from the dataset: Calculate the factorial of a number using recursion.\n",
            "User Prompt: calculate the factorial of a number using recursion.\n",
            "Corresponding Original Mermaid Code: graph TD\n",
            "    A((Start)) --> B[/\"Input number n\"/]\n",
            "    B --> C(\"Base case: n=0 or n=1?\")\n",
            "    C -->|Yes| D[\"Factorial is 1\"]\n",
            "    C -->|No| E[\"Recursively call factorial(n-1)\"]\n",
            "    E --> F[\"Multiply result by n\"]\n",
            "    F --> G[\"Output Factorial\"]\n",
            "    G --> H((End))\n",
            "\n",
            "Generated Mermaid Code: Calculez le factorial d'un nombre en utilisant la recursion\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# User enters a prompt from the dataset\n",
        "user_prompt = input(\"Enter a prompt from the dataset: \").lower()\n",
        "\n",
        "# Find the corresponding Mermaid code in the dataset\n",
        "corresponding_mermaid_code = data[data[\"Prompt\"].str.lower() == user_prompt][\"Mermaid_code\"].values\n",
        "\n",
        "# Tokenize the user's prompt\n",
        "tokenized_user_prompt = tokenizer(user_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Generate Mermaid code using the pre-trained T5 model\n",
        "generated_mermaid_code = model.generate(**tokenized_user_prompt)\n",
        "\n",
        "# Convert token IDs back to text for both generated and original codes\n",
        "generated_mermaid_code_text = tokenizer.batch_decode(generated_mermaid_code, skip_special_tokens=True)\n",
        "\n",
        "# Print the results\n",
        "print(f\"User Prompt: {user_prompt}\")\n",
        "\n",
        "if len(corresponding_mermaid_code) > 0:\n",
        "    print(f\"Corresponding Original Mermaid Code: {corresponding_mermaid_code[0]}\")\n",
        "else:\n",
        "    print(\"Prompt not found in the dataset.\")\n",
        "\n",
        "print(f\"Generated Mermaid Code: {generated_mermaid_code_text[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n"
      ],
      "metadata": {
        "id": "4NbBfOZQwncm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
        "data = pd.read_csv('flowchart-mermaid.csv')\n",
        "\n",
        "# Preprocess prompts\n",
        "data[\"Prompt\"] = data[\"Prompt\"].astype(str).str.lower()"
      ],
      "metadata": {
        "id": "hlUfwqTbwrA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize prompts\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[\"Prompt\"])\n",
        "sequences = tokenizer.texts_to_sequences(data[\"Prompt\"])\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n"
      ],
      "metadata": {
        "id": "ClmPQqoBwuX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Mermaid_code to numerical format\n",
        "tokenizer_targets = Tokenizer()\n",
        "tokenizer_targets.fit_on_texts(data[\"Mermaid_code\"])\n",
        "sequences_targets = tokenizer_targets.texts_to_sequences(data[\"Mermaid_code\"])\n",
        "\n",
        "# Pad sequences_targets\n",
        "max_sequence_length_targets = max([len(seq) for seq in sequences_targets])\n",
        "padded_sequences_targets = pad_sequences(sequences_targets, maxlen=max_sequence_length_targets, padding='post')\n"
      ],
      "metadata": {
        "id": "jmlohNCRxLut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
        "encoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100)(encoder_inputs)\n",
        "encoder_lstm, state_h, state_c = tf.keras.layers.LSTM(100, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))  # None for variable length\n",
        "decoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer_targets.word_index) + 1, output_dim=100)(decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_outputs = tf.keras.layers.Dense(len(tokenizer_targets.word_index) + 1, activation='softmax')(decoder_lstm)\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([padded_sequences, padded_sequences_targets[:, :-1]], padded_sequences_targets[:, 1:], epochs=100, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E-Lc12Ewwg7",
        "outputId": "ebcf4a03-0fca-4505-c77d-f26bce34c6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 7s 589ms/step - loss: 6.7893 - accuracy: 0.1242 - val_loss: 6.7546 - val_accuracy: 0.5823\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 190ms/step - loss: 6.7085 - accuracy: 0.8497 - val_loss: 6.6588 - val_accuracy: 0.5802\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 194ms/step - loss: 6.5166 - accuracy: 0.8488 - val_loss: 6.3333 - val_accuracy: 0.5800\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 156ms/step - loss: 5.9141 - accuracy: 0.8485 - val_loss: 5.7228 - val_accuracy: 0.5776\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 5.0746 - accuracy: 0.8464 - val_loss: 5.1906 - val_accuracy: 0.5776\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 4.3580 - accuracy: 0.8464 - val_loss: 4.7024 - val_accuracy: 0.5776\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 199ms/step - loss: 3.6840 - accuracy: 0.8464 - val_loss: 4.2199 - val_accuracy: 0.5776\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 3.0140 - accuracy: 0.8464 - val_loss: 3.7676 - val_accuracy: 0.5776\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 128ms/step - loss: 2.3743 - accuracy: 0.8464 - val_loss: 3.4188 - val_accuracy: 0.5776\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 1.8519 - accuracy: 0.8464 - val_loss: 3.2382 - val_accuracy: 0.5776\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.5007 - accuracy: 0.8464 - val_loss: 3.2197 - val_accuracy: 0.5776\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 1.3199 - accuracy: 0.8464 - val_loss: 3.2924 - val_accuracy: 0.5776\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 302ms/step - loss: 1.2437 - accuracy: 0.8464 - val_loss: 3.3823 - val_accuracy: 0.5776\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 197ms/step - loss: 1.2047 - accuracy: 0.8464 - val_loss: 3.4485 - val_accuracy: 0.5776\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 1.1758 - accuracy: 0.8464 - val_loss: 3.4864 - val_accuracy: 0.5776\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 1s 187ms/step - loss: 1.1440 - accuracy: 0.8464 - val_loss: 3.4970 - val_accuracy: 0.5776\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 1.1082 - accuracy: 0.8464 - val_loss: 3.4844 - val_accuracy: 0.5776\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 1.0730 - accuracy: 0.8464 - val_loss: 3.4586 - val_accuracy: 0.5776\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 137ms/step - loss: 1.0418 - accuracy: 0.8464 - val_loss: 3.4261 - val_accuracy: 0.5776\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0207 - accuracy: 0.8464 - val_loss: 3.3992 - val_accuracy: 0.5776\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 161ms/step - loss: 1.0115 - accuracy: 0.8464 - val_loss: 3.3905 - val_accuracy: 0.5776\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 1.0026 - accuracy: 0.8464 - val_loss: 3.4038 - val_accuracy: 0.5776\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 166ms/step - loss: 0.9926 - accuracy: 0.8464 - val_loss: 3.4307 - val_accuracy: 0.5776\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 189ms/step - loss: 0.9817 - accuracy: 0.8464 - val_loss: 3.4656 - val_accuracy: 0.5776\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.9725 - accuracy: 0.8464 - val_loss: 3.4965 - val_accuracy: 0.5776\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 0.9666 - accuracy: 0.8464 - val_loss: 3.5201 - val_accuracy: 0.5776\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 178ms/step - loss: 0.9598 - accuracy: 0.8464 - val_loss: 3.5281 - val_accuracy: 0.5776\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.9529 - accuracy: 0.8464 - val_loss: 3.5279 - val_accuracy: 0.5776\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 145ms/step - loss: 0.9456 - accuracy: 0.8464 - val_loss: 3.5301 - val_accuracy: 0.5776\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 0.9387 - accuracy: 0.8464 - val_loss: 3.5294 - val_accuracy: 0.5776\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 0.9328 - accuracy: 0.8464 - val_loss: 3.5250 - val_accuracy: 0.5776\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9265 - accuracy: 0.8464 - val_loss: 3.5321 - val_accuracy: 0.5776\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 123ms/step - loss: 0.9194 - accuracy: 0.8464 - val_loss: 3.5466 - val_accuracy: 0.5776\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 0.9122 - accuracy: 0.8467 - val_loss: 3.5641 - val_accuracy: 0.5800\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 0.9039 - accuracy: 0.8486 - val_loss: 3.5693 - val_accuracy: 0.5800\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.8961 - accuracy: 0.8486 - val_loss: 3.5012 - val_accuracy: 0.5798\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 166ms/step - loss: 0.8885 - accuracy: 0.8487 - val_loss: 3.5431 - val_accuracy: 0.5803\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 1s 177ms/step - loss: 0.8802 - accuracy: 0.8491 - val_loss: 3.5271 - val_accuracy: 0.5808\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 370ms/step - loss: 0.8738 - accuracy: 0.8499 - val_loss: 3.5272 - val_accuracy: 0.5808\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 144ms/step - loss: 0.8680 - accuracy: 0.8506 - val_loss: 3.5281 - val_accuracy: 0.5838\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.8644 - accuracy: 0.8523 - val_loss: 3.5109 - val_accuracy: 0.5827\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8572 - accuracy: 0.8547 - val_loss: 3.5338 - val_accuracy: 0.5831\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.8522 - accuracy: 0.8553 - val_loss: 3.5539 - val_accuracy: 0.5842\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 0.8476 - accuracy: 0.8556 - val_loss: 3.5518 - val_accuracy: 0.5846\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 174ms/step - loss: 0.8414 - accuracy: 0.8558 - val_loss: 3.5564 - val_accuracy: 0.5850\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 127ms/step - loss: 0.8340 - accuracy: 0.8562 - val_loss: 3.5471 - val_accuracy: 0.5858\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 0.8277 - accuracy: 0.8567 - val_loss: 3.5368 - val_accuracy: 0.5868\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.8225 - accuracy: 0.8576 - val_loss: 3.5624 - val_accuracy: 0.5872\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8164 - accuracy: 0.8577 - val_loss: 3.5381 - val_accuracy: 0.5877\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.8096 - accuracy: 0.8578 - val_loss: 3.5511 - val_accuracy: 0.5874\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 1s 163ms/step - loss: 0.8047 - accuracy: 0.8578 - val_loss: 3.5628 - val_accuracy: 0.5874\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 216ms/step - loss: 0.7993 - accuracy: 0.8583 - val_loss: 3.5418 - val_accuracy: 0.5877\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.7947 - accuracy: 0.8591 - val_loss: 3.5777 - val_accuracy: 0.5899\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.7896 - accuracy: 0.8595 - val_loss: 3.5781 - val_accuracy: 0.5901\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 212ms/step - loss: 0.7858 - accuracy: 0.8602 - val_loss: 3.5941 - val_accuracy: 0.5904\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.7820 - accuracy: 0.8608 - val_loss: 3.5882 - val_accuracy: 0.5905\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.7779 - accuracy: 0.8616 - val_loss: 3.6057 - val_accuracy: 0.5904\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 177ms/step - loss: 0.7744 - accuracy: 0.8613 - val_loss: 3.5925 - val_accuracy: 0.5907\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 139ms/step - loss: 0.7712 - accuracy: 0.8622 - val_loss: 3.6084 - val_accuracy: 0.5909\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 1s 309ms/step - loss: 0.7681 - accuracy: 0.8624 - val_loss: 3.6157 - val_accuracy: 0.5912\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 129ms/step - loss: 0.7654 - accuracy: 0.8626 - val_loss: 3.6099 - val_accuracy: 0.5927\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 140ms/step - loss: 0.7639 - accuracy: 0.8633 - val_loss: 3.6527 - val_accuracy: 0.5913\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.7605 - accuracy: 0.8631 - val_loss: 3.6341 - val_accuracy: 0.5915\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.7574 - accuracy: 0.8632 - val_loss: 3.6322 - val_accuracy: 0.5916\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.7550 - accuracy: 0.8631 - val_loss: 3.6434 - val_accuracy: 0.5920\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 180ms/step - loss: 0.7524 - accuracy: 0.8633 - val_loss: 3.6750 - val_accuracy: 0.5919\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 301ms/step - loss: 0.7499 - accuracy: 0.8632 - val_loss: 3.6780 - val_accuracy: 0.5927\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 167ms/step - loss: 0.7476 - accuracy: 0.8634 - val_loss: 3.6867 - val_accuracy: 0.5920\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.7453 - accuracy: 0.8634 - val_loss: 3.6923 - val_accuracy: 0.5920\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.7497 - accuracy: 0.8629 - val_loss: 3.7090 - val_accuracy: 0.5913\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.7426 - accuracy: 0.8633 - val_loss: 3.6964 - val_accuracy: 0.5927\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.7430 - accuracy: 0.8636 - val_loss: 3.7765 - val_accuracy: 0.5920\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 174ms/step - loss: 0.7422 - accuracy: 0.8635 - val_loss: 3.7001 - val_accuracy: 0.5919\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.7391 - accuracy: 0.8636 - val_loss: 3.7324 - val_accuracy: 0.5917\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.7368 - accuracy: 0.8634 - val_loss: 3.7184 - val_accuracy: 0.5935\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 0.7341 - accuracy: 0.8637 - val_loss: 3.7505 - val_accuracy: 0.5912\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7322 - accuracy: 0.8635 - val_loss: 3.7176 - val_accuracy: 0.5915\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7302 - accuracy: 0.8639 - val_loss: 3.7367 - val_accuracy: 0.5920\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 193ms/step - loss: 0.7279 - accuracy: 0.8637 - val_loss: 3.7476 - val_accuracy: 0.5934\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.7254 - accuracy: 0.8639 - val_loss: 3.7231 - val_accuracy: 0.5940\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.7234 - accuracy: 0.8638 - val_loss: 3.7297 - val_accuracy: 0.5928\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.7212 - accuracy: 0.8638 - val_loss: 3.7462 - val_accuracy: 0.5939\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.7192 - accuracy: 0.8639 - val_loss: 3.7601 - val_accuracy: 0.5946\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.7172 - accuracy: 0.8640 - val_loss: 3.7754 - val_accuracy: 0.5946\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 115ms/step - loss: 0.7155 - accuracy: 0.8638 - val_loss: 3.7787 - val_accuracy: 0.5950\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 0.7134 - accuracy: 0.8641 - val_loss: 3.7968 - val_accuracy: 0.5943\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 165ms/step - loss: 0.7118 - accuracy: 0.8639 - val_loss: 3.7722 - val_accuracy: 0.5962\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.7104 - accuracy: 0.8642 - val_loss: 3.8011 - val_accuracy: 0.5935\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 0.7082 - accuracy: 0.8638 - val_loss: 3.7901 - val_accuracy: 0.5960\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.7063 - accuracy: 0.8642 - val_loss: 3.8262 - val_accuracy: 0.5944\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.7042 - accuracy: 0.8639 - val_loss: 3.8075 - val_accuracy: 0.5960\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.7022 - accuracy: 0.8641 - val_loss: 3.8298 - val_accuracy: 0.5950\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.7005 - accuracy: 0.8638 - val_loss: 3.8096 - val_accuracy: 0.5964\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.6991 - accuracy: 0.8642 - val_loss: 3.8424 - val_accuracy: 0.5947\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.6964 - accuracy: 0.8640 - val_loss: 3.8300 - val_accuracy: 0.5958\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 121ms/step - loss: 0.6945 - accuracy: 0.8645 - val_loss: 3.8358 - val_accuracy: 0.5955\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.6925 - accuracy: 0.8644 - val_loss: 3.8544 - val_accuracy: 0.5951\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.6908 - accuracy: 0.8644 - val_loss: 3.8346 - val_accuracy: 0.5959\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 114ms/step - loss: 0.6889 - accuracy: 0.8652 - val_loss: 3.8792 - val_accuracy: 0.5946\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.6869 - accuracy: 0.8657 - val_loss: 3.8660 - val_accuracy: 0.5952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b922c986260>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([padded_sequences, padded_sequences_targets[:, :-1]], padded_sequences_targets[:, 1:])\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHWaU4kax5xK",
        "outputId": "fae7350d-e4f3-4f7b-d073-4bb20ea7e197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3285 - accuracy: 0.8114\n",
            "Loss: 1.3284941911697388\n",
            "Accuracy: 0.8114491105079651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define input layers\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(max_sequence_length,))\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))  # None for variable length\n",
        "\n",
        "# Define embedding layers\n",
        "encoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100)(encoder_inputs)\n",
        "decoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer_targets.word_index) + 1, output_dim=100)(decoder_inputs)\n",
        "\n",
        "# Define LSTM layers\n",
        "encoder_lstm = tf.keras.layers.LSTM(100, return_state=True)\n",
        "decoder_lstm = tf.keras.layers.LSTM(100, return_sequences=True)\n",
        "\n",
        "# Encoder LSTM layer\n",
        "encoder_lstm_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder LSTM layer\n",
        "decoder_lstm_outputs = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Define output layer (Dense layer with softmax activation)\n",
        "decoder_outputs = tf.keras.layers.Dense(len(tokenizer_targets.word_index) + 1, activation='softmax')(decoder_lstm_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ],
      "metadata": {
        "id": "iHId1HwizYgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print individual layers\n",
        "for layer in model.layers:\n",
        "    print(layer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbz5-DqazkII",
        "outputId": "e0901622-442e-42db-cf31-fdb02c444475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.engine.input_layer.InputLayer object at 0x7b922cc81cf0>\n",
            "<keras.src.engine.input_layer.InputLayer object at 0x7b922cc83460>\n",
            "<keras.src.layers.core.embedding.Embedding object at 0x7b922cc81d20>\n",
            "<keras.src.layers.core.embedding.Embedding object at 0x7b922cc2f010>\n",
            "<keras.src.layers.rnn.lstm.LSTM object at 0x7b922cc2e770>\n",
            "<keras.src.layers.rnn.lstm.LSTM object at 0x7b922cca0a60>\n",
            "<keras.src.layers.core.dense.Dense object at 0x7b922cbd7a90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiBQQAe8zma4",
        "outputId": "cebe9d4f-bb32-494a-a374-b2cff42b9b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 53)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)     (None, 53, 100)              32200     ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_9 (Embedding)     (None, None, 100)            89900     ['input_8[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_8 (LSTM)               [(None, 100),                80400     ['embedding_8[0][0]']         \n",
            "                              (None, 100),                                                        \n",
            "                              (None, 100)]                                                        \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)               (None, None, 100)            80400     ['embedding_9[0][0]',         \n",
            "                                                                     'lstm_8[0][1]',              \n",
            "                                                                     'lstm_8[0][2]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, None, 899)            90799     ['lstm_9[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 373699 (1.43 MB)\n",
            "Trainable params: 373699 (1.43 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Existing prompt to test the model\n",
        "existing_prompt = \"Calculate the factorial of a number using recursion.\"  # Change this to your desired prompt\n",
        "\n",
        "# Preprocess the existing prompt\n",
        "existing_prompt_sequence = tokenizer.texts_to_sequences([existing_prompt])\n",
        "padded_existing_prompt_sequence = pad_sequences(existing_prompt_sequence, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Generate the flowchart code using the model\n",
        "generated_flowchart_code = model.predict([padded_existing_prompt_sequence, np.zeros((1, max_sequence_length_targets - 1))])\n",
        "\n",
        "generated_flowchart_code_text = ''\n",
        "for token_index in np.argmax(generated_flowchart_code[0], axis=-1):\n",
        "    if token_index == 0:\n",
        "        break  # End of sequence token\n",
        "    word = tokenizer_targets.index_word.get(token_index, '<UNK>')  # Replace unknown tokens with '<UNK>'\n",
        "    generated_flowchart_code_text += word + ' '\n",
        "\n",
        "# Retrieve the expected flowchart code from the dataset\n",
        "expected_flowchart_code = data[data[\"Prompt\"].str.lower() == existing_prompt.lower()][\"Mermaid_code\"].values[0]\n",
        "\n",
        "# Compare the generated flowchart code with the expected flowchart code\n",
        "print(\"Existing Prompt:\", existing_prompt)\n",
        "print(\"Expected Flowchart Code:\", expected_flowchart_code)\n",
        "print(\"Generated Flowchart Code:\", generated_flowchart_code_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9KV8ClWyCe2",
        "outputId": "0f9c5b86-d2ef-4f2c-e254-b2b04e0d1464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 660ms/step\n",
            "Existing Prompt: Calculate the factorial of a number using recursion.\n",
            "Expected Flowchart Code: graph TD\n",
            "    A((Start)) --> B[/\"Input number n\"/]\n",
            "    B --> C(\"Base case: n=0 or n=1?\")\n",
            "    C -->|Yes| D[\"Factorial is 1\"]\n",
            "    C -->|No| E[\"Recursively call factorial(n-1)\"]\n",
            "    E --> F[\"Multiply result by n\"]\n",
            "    F --> G[\"Output Factorial\"]\n",
            "    G --> H((End))\n",
            "\n",
            " \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8820181c65b44f794d90b1b3880a210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149e2723a3904917b10669eba70acec1",
              "IPY_MODEL_18358d2c1ef5488a9ec0b95e76cdbf5b",
              "IPY_MODEL_38019b9303524216b5e722a849168899"
            ],
            "layout": "IPY_MODEL_21eb99198ddf4f99943fa8974ee46992"
          }
        },
        "149e2723a3904917b10669eba70acec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f63418571ae4a06b7c65f654816dfd5",
            "placeholder": "​",
            "style": "IPY_MODEL_c777542fac0c46238447e0424d54b033",
            "value": "config.json: 100%"
          }
        },
        "18358d2c1ef5488a9ec0b95e76cdbf5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e84d8d755a4e24a2db7752052862af",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37b9cb998f0c40cb949b63d5ac36c2ca",
            "value": 1585
          }
        },
        "38019b9303524216b5e722a849168899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb1935a77e2243b48214e8646ca91c21",
            "placeholder": "​",
            "style": "IPY_MODEL_b3903f62af3e493a8143fe3e3419ec9a",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 75.8kB/s]"
          }
        },
        "21eb99198ddf4f99943fa8974ee46992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f63418571ae4a06b7c65f654816dfd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c777542fac0c46238447e0424d54b033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46e84d8d755a4e24a2db7752052862af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b9cb998f0c40cb949b63d5ac36c2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb1935a77e2243b48214e8646ca91c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3903f62af3e493a8143fe3e3419ec9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5bed83e801843cc967b8bf6cfea9049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f42f347a25ba473dbc35bbc5ad5f2af6",
              "IPY_MODEL_945eed4f884f4d6384be80c119724b9b",
              "IPY_MODEL_fb5a4e6268074fcebdf1fc44de39dca8"
            ],
            "layout": "IPY_MODEL_4570bf4207834f0b91ea8c8a03065712"
          }
        },
        "f42f347a25ba473dbc35bbc5ad5f2af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13bf6b132e544dcfa32b100e9d7142fb",
            "placeholder": "​",
            "style": "IPY_MODEL_5f774e82b0ee49f3b26aeb625da916fc",
            "value": "vocab.json: 100%"
          }
        },
        "945eed4f884f4d6384be80c119724b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e307ef6433cb4eb3bd300bd70b8db3d0",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b792cd3e97e1441fbc6cb6b9d43083c5",
            "value": 898823
          }
        },
        "fb5a4e6268074fcebdf1fc44de39dca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b32d3b2e3644b8b5a74f1f0d46e017",
            "placeholder": "​",
            "style": "IPY_MODEL_d18c64acd0174e589c963438b44ef012",
            "value": " 899k/899k [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "4570bf4207834f0b91ea8c8a03065712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13bf6b132e544dcfa32b100e9d7142fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f774e82b0ee49f3b26aeb625da916fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e307ef6433cb4eb3bd300bd70b8db3d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b792cd3e97e1441fbc6cb6b9d43083c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12b32d3b2e3644b8b5a74f1f0d46e017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18c64acd0174e589c963438b44ef012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91bd9dd7c9b1446990c6749376e99c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fc2ca54083049cbb2b31b966a24a533",
              "IPY_MODEL_088b763ae19b420397caff9644488f2d",
              "IPY_MODEL_f7a01d9838b14204aeeb6d37b48cf118"
            ],
            "layout": "IPY_MODEL_faea9eeb151c4cf49987e9c5a7409485"
          }
        },
        "7fc2ca54083049cbb2b31b966a24a533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8d3d4b126744429cb5e4f535b3629f",
            "placeholder": "​",
            "style": "IPY_MODEL_add7944ef6d64ce2b231dd53f3d177ed",
            "value": "merges.txt: 100%"
          }
        },
        "088b763ae19b420397caff9644488f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79735f8d946c45e8960d084c06fefb6f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd2bd90064e14a11b7a2669c17e4bc14",
            "value": 456318
          }
        },
        "f7a01d9838b14204aeeb6d37b48cf118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f5bcee0be7c434294000fed76d53a30",
            "placeholder": "​",
            "style": "IPY_MODEL_f44884fe540f458ebf1eae647b3b9463",
            "value": " 456k/456k [00:00&lt;00:00, 24.3MB/s]"
          }
        },
        "faea9eeb151c4cf49987e9c5a7409485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8d3d4b126744429cb5e4f535b3629f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "add7944ef6d64ce2b231dd53f3d177ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79735f8d946c45e8960d084c06fefb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2bd90064e14a11b7a2669c17e4bc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f5bcee0be7c434294000fed76d53a30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44884fe540f458ebf1eae647b3b9463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57ea9c64588e460f8e9bb27a52cb709e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cde0b2ddea4646578cc687ee196c136c",
              "IPY_MODEL_d31e2bcff9594aadbf1445d469ca115b",
              "IPY_MODEL_1c6ec0bc25b94f05b3e2d73e088d9acf"
            ],
            "layout": "IPY_MODEL_42c03bfbf5744103a25ec4f56a83a65a"
          }
        },
        "cde0b2ddea4646578cc687ee196c136c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_343f7c7b826145d49e1d1b47795b8a98",
            "placeholder": "​",
            "style": "IPY_MODEL_446e32d428314b4487cb570f12a8e9cf",
            "value": "tokenizer.json: 100%"
          }
        },
        "d31e2bcff9594aadbf1445d469ca115b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c828767deb74a60bae801fba1d45260",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a23ad9ef5b5f454baf7a6f34035a0a6f",
            "value": 1355863
          }
        },
        "1c6ec0bc25b94f05b3e2d73e088d9acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96247457ece4f5e8aa656374a63aad9",
            "placeholder": "​",
            "style": "IPY_MODEL_a533b5e53b9242de8e4e6fc747684759",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 18.9MB/s]"
          }
        },
        "42c03bfbf5744103a25ec4f56a83a65a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "343f7c7b826145d49e1d1b47795b8a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "446e32d428314b4487cb570f12a8e9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c828767deb74a60bae801fba1d45260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23ad9ef5b5f454baf7a6f34035a0a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d96247457ece4f5e8aa656374a63aad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a533b5e53b9242de8e4e6fc747684759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ba55f08e05a484f9211fb0667a3ec9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_167d7760959e4ce7a594b2898b59ff39",
              "IPY_MODEL_c2cc832b705d4eaaa0010a56af8780e0",
              "IPY_MODEL_e296dfaa8958467697ee0f1235514208"
            ],
            "layout": "IPY_MODEL_ba639df59a954c2896beb9055658e973"
          }
        },
        "167d7760959e4ce7a594b2898b59ff39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf03f3749ab0425792ce161674018194",
            "placeholder": "​",
            "style": "IPY_MODEL_dccec88eb1504ffc863ad3922b211969",
            "value": "model.safetensors: 100%"
          }
        },
        "c2cc832b705d4eaaa0010a56af8780e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3169bcec34946b0a4d3930a1d8659c0",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c913193c4f5c4944baca8fb4b5d0052b",
            "value": 1625222120
          }
        },
        "e296dfaa8958467697ee0f1235514208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b293eafc38d44d4aa6db5832f8510389",
            "placeholder": "​",
            "style": "IPY_MODEL_1e2b748b039a4a6cbd64e410bb540d49",
            "value": " 1.63G/1.63G [00:10&lt;00:00, 174MB/s]"
          }
        },
        "ba639df59a954c2896beb9055658e973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf03f3749ab0425792ce161674018194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccec88eb1504ffc863ad3922b211969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3169bcec34946b0a4d3930a1d8659c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c913193c4f5c4944baca8fb4b5d0052b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b293eafc38d44d4aa6db5832f8510389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2b748b039a4a6cbd64e410bb540d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d269f4ba3bb3438ba84bf3736d5cb903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f9113ef9eb746bcb335061ed44393bc",
              "IPY_MODEL_d9d42c144c9847eb921c714416606478",
              "IPY_MODEL_b38a1264d2ee4ea783154c218923d738"
            ],
            "layout": "IPY_MODEL_1336d10ea7cc42209efe0ca512fbae5e"
          }
        },
        "7f9113ef9eb746bcb335061ed44393bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dcf81fdc8e147a48381cf0be0e140ff",
            "placeholder": "​",
            "style": "IPY_MODEL_db6505c8efdb4bd581a1b91153e6a6a3",
            "value": "generation_config.json: 100%"
          }
        },
        "d9d42c144c9847eb921c714416606478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed63128bd1c040388d6f93b80e0a8662",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e31137e682b44f95ae88f7557fcc1ee4",
            "value": 363
          }
        },
        "b38a1264d2ee4ea783154c218923d738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39af302553634ea08355daf92f9724ef",
            "placeholder": "​",
            "style": "IPY_MODEL_18a714d9eacd4df8ba58c329549ea098",
            "value": " 363/363 [00:00&lt;00:00, 6.54kB/s]"
          }
        },
        "1336d10ea7cc42209efe0ca512fbae5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dcf81fdc8e147a48381cf0be0e140ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6505c8efdb4bd581a1b91153e6a6a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed63128bd1c040388d6f93b80e0a8662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31137e682b44f95ae88f7557fcc1ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39af302553634ea08355daf92f9724ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a714d9eacd4df8ba58c329549ea098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}